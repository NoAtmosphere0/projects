{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b76YngfGGfyD"
   },
   "source": [
    "# Lab03: Decision Tree\n",
    "\n",
    "\n",
    "Student ID: 21127347  \n",
    "\n",
    "Student name: Đặng Hoàng Long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xZqh-Z7GfyF"
   },
   "source": [
    "*This notebook is a lab assignment of the Artificial Intelligence course (CSC14003). The lab aims to familiarize students with the essence of Decision Trees, more specifically Iterative Dichotomiser 3 (ID3).*\n",
    "During the lab, I've learned a few things:\n",
    "- How to implement ID3 algorithm\n",
    "- How to use ID3 algorithm to solve a classification problem\n",
    "- How to evaluate the performance of a classifier using the confusion matrix, more specifically:\n",
    "  - Accuracy\n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1 score\n",
    "- The math behind the ID3 algorithm, such as\n",
    "  - Entropy\n",
    "  - Information Gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--NRbml7GfyG"
   },
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VhR1GCY5GfyH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-OzYr2SGfyN"
   },
   "source": [
    "### Load Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oX5c3r4uGfyO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "#split dataset into training data and testing data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "US1KgZBgGfyU"
   },
   "source": [
    "## 1. Decision Tree: Iterative Dichotomiser 3 (ID3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4sQh1ieuGfyV"
   },
   "source": [
    "### 1.1 Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSjCJR_eGfyV"
   },
   "source": [
    "Expected value of the self-information (entropy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZM7fmb0GfyW"
   },
   "source": [
    "$$Entropy=-\\sum_{i}^{n}p_ilog_{2}(p_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDjtCHd_GfyX"
   },
   "source": [
    "The entropy function gets the smallest value if there is a value of $p_i$ equal to 1, reaches the maximum value if all $ p_i $ are equal. These properties of the entropy function make it is an expression of the disorder, or randomness of a system, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kql-MFq-GfyX"
   },
   "outputs": [],
   "source": [
    "def entropy(counts, n_samples):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    counts: shape (n_classes): list number of samples in each class\n",
    "    n_samples: number of data samples\n",
    "    \n",
    "    -----------\n",
    "    return entropy \n",
    "    \"\"\"\n",
    "    entropy = 0\n",
    "    for count in counts:\n",
    "        if count != 0:\n",
    "            entropy += -count/n_samples * np.log2(count/n_samples)\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsGJfLhmGfyc"
   },
   "outputs": [],
   "source": [
    "def entropy_of_one_division(division): \n",
    "    \"\"\"\n",
    "    Returns entropy of a divided group of data\n",
    "    Data may have multiple classes\n",
    "    \"\"\"\n",
    "    n_samples = len(division)\n",
    "    n_classes = set(division)\n",
    "    \n",
    "    counts=[]\n",
    "    #count samples in each class then store it to list counts\n",
    "    for c in n_classes:\n",
    "        counts.append(sum(division==c))\n",
    "\n",
    "    #calculate entropy of each class\n",
    "    e = entropy(counts,n_samples)\n",
    "    \n",
    "    return e,n_samples\n",
    "\n",
    "\n",
    "def get_entropy(y_predict, y):\n",
    "    \"\"\"\n",
    "    Returns entropy of a split\n",
    "    y_predict is the split decision by cutoff, True/Fasle\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    entropy_true, n_true = entropy_of_one_division(y[y_predict]) # left hand side entropy\n",
    "    entropy_false, n_false = entropy_of_one_division(y[~y_predict]) # right hand side entropy\n",
    "    # overall entropy\n",
    "    s =  n_true/n * entropy_true + n_false/n * entropy_false\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWhnKZm9Gfyi"
   },
   "source": [
    "The information gain of classifying information set D by attribute A:\n",
    "$$ Gain(A)=Entrophy(D)-Entrophy_{A}(D)$$\n",
    "\n",
    "At each node in ID3, an attribute is chosen if its information gain is highest compare to others.\n",
    "\n",
    "All attributes of the Iris set are represented by continuous values. Therefore we need to represent them with discrete values. The simple way is to use a `cutoff` threshold to separate values of the data on each attribute into two part:` <cutoff` and `> = cutoff`.\n",
    "\n",
    "To find the best `cutoff` for an attribute, we replace` cutoff` with its values then compute the entropy, best `cutoff` achieved when value of entropy is smallest  $ \\left (\\arg \\min Entrophy_ {A} (D) \\right) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTKwaSw-Gfyj"
   },
   "source": [
    "### 1.2 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xp6omaz2Gfyj"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, tree=None, depth=0):\n",
    "        '''Parameters:\n",
    "        -----------------\n",
    "        tree: decision tree\n",
    "        depth: depth of decision tree after training'''\n",
    "        \n",
    "        self.depth = depth\n",
    "        self.tree=tree\n",
    "    def fit(self, X, y, node={}, depth=0):\n",
    "        '''Parameter:\n",
    "        -----------------\n",
    "        X: training data\n",
    "        y: label of training data\n",
    "        ------------------\n",
    "        return: node \n",
    "        \n",
    "        node: each node represented by cutoff value and column index, value and children.\n",
    "         - cutoff value is thresold where you divide your attribute\n",
    "         - column index is your data attribute index\n",
    "         - value of node is mean value of label indexes, \n",
    "           if a node is leaf all data samples will have same label\n",
    "        \n",
    "        Note that: we divide each attribute into 2 part => each node will have 2 children: left, right.\n",
    "        '''\n",
    "        \n",
    "        #Stop conditions\n",
    "        \n",
    "        #if all value of y are the same \n",
    "        if np.all(y==y[0]):\n",
    "            return {'val':y[0]}\n",
    "\n",
    "        else: \n",
    "            col_idx, cutoff, entropy = self.find_best_split_of_all(X, y)    # find one split given an information gain \n",
    "            y_left = y[X[:, col_idx] < cutoff]\n",
    "            y_right = y[X[:, col_idx] >= cutoff]\n",
    "            node = {'index_col':col_idx,\n",
    "                        'cutoff':cutoff,\n",
    "                   'val':np.mean(y)}\n",
    "            node['left'] = self.fit(X[X[:, col_idx] < cutoff], y_left, {}, depth+1)\n",
    "            node['right'] = self.fit(X[X[:, col_idx] >= cutoff], y_right, {}, depth+1)\n",
    "            self.depth += 1 \n",
    "            self.tree = node\n",
    "            return node\n",
    "    \n",
    "    def find_best_split_of_all(self, X, y):\n",
    "        col_idx = None\n",
    "        min_entropy = 1\n",
    "        cutoff = None\n",
    "        for i, col_data in enumerate(X.T):\n",
    "            entropy, cur_cutoff = self.find_best_split(col_data, y)\n",
    "            if entropy == 0:                   #best entropy\n",
    "                return i, cur_cutoff, entropy\n",
    "            elif entropy <= min_entropy:\n",
    "                min_entropy = entropy\n",
    "                col_idx = i\n",
    "                cutoff = cur_cutoff\n",
    "               \n",
    "        return col_idx, cutoff, min_entropy\n",
    "    \n",
    "    def find_best_split(self, col_data, y):\n",
    "        ''' Parameters:\n",
    "        -------------\n",
    "        col_data: data samples in column'''\n",
    "         \n",
    "        min_entropy = 10\n",
    "\n",
    "        #Loop through col_data find cutoff where entropy is minimum\n",
    "\n",
    "\n",
    "        for value in set(col_data):\n",
    "            y_predict = col_data < value\n",
    "            my_entropy = get_entropy(y_predict, y)\n",
    "            #TODO\n",
    "            if my_entropy < min_entropy:\n",
    "                min_entropy = my_entropy\n",
    "                cutoff = value\n",
    "            \n",
    "        return min_entropy, cutoff\n",
    "                                               \n",
    "    def predict(self, X):\n",
    "        tree = self.tree\n",
    "        pred = np.zeros(shape=len(X))\n",
    "        for i, c in enumerate(X):\n",
    "            pred[i] = self._predict(c)\n",
    "        return pred\n",
    "    \n",
    "    def _predict(self, row):\n",
    "        cur_layer = self.tree\n",
    "        while cur_layer.get('cutoff'):\n",
    "            if row[cur_layer['index_col']] < cur_layer['cutoff']:\n",
    "                cur_layer = cur_layer['left']\n",
    "            else:\n",
    "                cur_layer = cur_layer['right']\n",
    "        else:\n",
    "            return cur_layer.get('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_OsIHd-Gfyq"
   },
   "source": [
    "### 1.3 Classification on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNgHip1dGfyr",
    "outputId": "12173b62-c713-4ad2-ca10-81d8addc7112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of your decision tree model on training data: 1.0\n",
      "Accuracy of your decision tree model: 0.96\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "tree = model.fit(X_train, y_train)\n",
    "pred=model.predict(X_train)\n",
    "print('Accuracy of your decision tree model on training data:', accuracy_score(y_train,pred))\n",
    "pred=model.predict(X_test)\n",
    "print('Accuracy of your decision tree model:', accuracy_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJaWYqt5Jvmp"
   },
   "source": [
    "**TODO**: F1, Recall and Precision report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 F1, Recall and Precision report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[50  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  1 49]]\n",
      "\n",
      "Accuracy: \n",
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load data\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Get shape of data\n",
    "#print(X.shape)\n",
    "#print(y)\n",
    "\n",
    "# Predict and print out the result\n",
    "y_pred = model.predict(X)\n",
    "print(\"\")\n",
    "#print(y_pred)\n",
    "\n",
    "# Get confusion matrix\n",
    "print(\"Confusion matrix: \")\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"\")\n",
    "print(cm)\n",
    "\n",
    "# Get accuracy\n",
    "print(\"\")\n",
    "print(\"Accuracy: \")\n",
    "print(accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get fancy and plot out the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(cm, cmap=plt.cm.viridis)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar(format='%1.d')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[50  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  1 49]]\n",
      "\n",
      "Class 1: \n",
      "True Positive:  50\n",
      "False Negative:  0\n",
      "False Positive:  0\n",
      "True Negative:  100\n",
      "\n",
      "Class 2: \n",
      "True Positive:  49\n",
      "False Negative:  1\n",
      "False Positive:  1\n",
      "True Negative:  99\n",
      "\n",
      "Class 3: \n",
      "True Positive:  49\n",
      "False Negative:  1\n",
      "False Positive:  1\n",
      "True Negative:  99\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix again\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# Get all the values from the confusion matrix\n",
    "\n",
    "# Value for the first class\n",
    "tp_1 = cm[0][0]\n",
    "fn_1 = cm[0][1] + cm[0][2]\n",
    "fp_1 = cm[1][0] + cm[2][0]\n",
    "tn_1 = cm[1][1] + cm[1][2] + cm[2][1] + cm[2][2]\n",
    "\n",
    "# Value for the second class\n",
    "tp_2 = cm[1][1]\n",
    "fn_2 = cm[1][0] + cm[1][2]\n",
    "fp_2 = cm[0][1] + cm[2][1]\n",
    "tn_2 = cm[0][0] + cm[0][2] + cm[2][0] + cm[2][2]\n",
    "\n",
    "# Value for the third class\n",
    "tp_3 = cm[2][2]\n",
    "fn_3 = cm[2][0] + cm[2][1]\n",
    "fp_3 = cm[0][2] + cm[1][2]\n",
    "tn_3 = cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1]\n",
    "\n",
    "print(\"\")\n",
    "print(\"Class 1: \")\n",
    "print(\"True Positive: \", tp_1)\n",
    "print(\"False Negative: \", fn_1)\n",
    "print(\"False Positive: \", fp_1)\n",
    "print(\"True Negative: \", tn_1)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Class 2: \")\n",
    "print(\"True Positive: \", tp_2)\n",
    "print(\"False Negative: \", fn_2)\n",
    "print(\"False Positive: \", fp_2)\n",
    "print(\"True Negative: \", tn_2)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Class 3: \")\n",
    "print(\"True Positive: \", tp_3)\n",
    "print(\"False Negative: \", fn_3)\n",
    "print(\"False Positive: \", fp_3)\n",
    "print(\"True Negative: \", tn_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get accuracy, precision and recall scores for the prediction**\n",
    "- *Accuracy*:\n",
    "\n",
    "$$accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "- *Precision*:\n",
    "$$precision=\\frac{TP}{TP+FP}$$\n",
    "\n",
    "- *Recall*:\n",
    "$$recall=\\frac{TP}{TP+FN}$$\n",
    "\n",
    "We will use the above formulas to calculate the accuracy, precision and recall scores for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 1:  1.0\n",
      "Precision for class 1:  1.0\n",
      "Recall for class 1:  1.0\n",
      "\n",
      "Accuracy for class 2:  0.9866666666666667\n",
      "Precision for class 2:  0.98\n",
      "Recall for class 2:  0.98\n",
      "\n",
      "Accuracy for class 3:  0.9866666666666667\n",
      "Precision for class 3:  0.98\n",
      "Recall for class 3:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Get the metrics for each of the three classes\n",
    "accuracy_1 = (tp_1 + tn_1) / (tp_1 + tn_1 + fp_1 + fn_1)\n",
    "precision_1 = tp_1 / (tp_1 + fp_1)\n",
    "recall_1 = tp_1 / (tp_1 + fn_1)\n",
    "print(\"Accuracy for class 1: \", accuracy_1)\n",
    "print(\"Precision for class 1: \", precision_1)\n",
    "print(\"Recall for class 1: \", recall_1)\n",
    "\n",
    "print(\"\")\n",
    "accuracy_2 = (tp_2 + tn_2) / (tp_2 + tn_2 + fp_2 + fn_2)\n",
    "precision_2 = tp_2 / (tp_2 + fp_2)\n",
    "recall_2 = tp_2 / (tp_2 + fn_2)\n",
    "print(\"Accuracy for class 2: \", accuracy_2)\n",
    "print(\"Precision for class 2: \", precision_2)\n",
    "print(\"Recall for class 2: \", recall_2)\n",
    "\n",
    "print(\"\")\n",
    "accuracy_3 = (tp_3 + tn_3) / (tp_3 + tn_3 + fp_3 + fn_3)\n",
    "precision_3 = tp_3 / (tp_3 + fp_3)\n",
    "recall_3 = tp_3 / (tp_3 + fn_3)\n",
    "print(\"Accuracy for class 3: \", accuracy_3)\n",
    "print(\"Precision for class 3: \", precision_3)\n",
    "print(\"Recall for class 3: \", recall_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the formula for calculating the F1 score is:\n",
    "\n",
    "$$F1 = 2 \\times \\frac{precision \\times recall}{precision + recall}$$\n",
    "\n",
    "F1 score is the harmonic mean of precision and recall. Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. As a result, the classifier will only get a high F1 score if both recall and precision are high.\n",
    "\n",
    "Let's calculate the F1 score for the classifier we trained on the last screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for class 1:  1.0\n",
      "F1 score for class 2:  0.98\n",
      "F1 score for class 3:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for each class\n",
    "f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1)\n",
    "f1_2 = 2 * (precision_2 * recall_2) / (precision_2 + recall_2)\n",
    "f1_3 = 2 * (precision_3 * recall_3) / (precision_3 + recall_3)\n",
    "\n",
    "print(\"F1 score for class 1: \", f1_1)\n",
    "print(\"F1 score for class 2: \", f1_2)\n",
    "print(\"F1 score for class 3: \", f1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [T. Tigerschiold, “What is Accuracy, Precision, Recall and F1 Score?,” Labelf.ai, Nov. 17, 2022. https://www.labelf.ai/blog/what-is-accuracy-precision-recall-and-f1-score (accessed Aug. 10, 2023)](https://www.labelf.ai/blog/what-is-accuracy-precision-recall-and-f1-score)  \n",
    "  \n",
    "- [“Precision, Recall, and F1 Score: When Accuracy Betrays You,” Proclus Academy, 2022. https://proclusacademy.com/blog/explainer/precision-recall-f1-score-classification-models/ (accessed Aug. 10, 2023)‌](https://proclusacademy.com/blog/explainer/precision-recall-f1-score-classification-models/)  \n",
    "  \n",
    "- [“Decision Trees: Information Gain.” Available: https://courses.cs.washington.edu/courses/cse446/20wi/Lecture3/03_InformationGain.pdf](https://courses.cs.washington.edu/courses/cse446/20wi/Lecture3/03_InformationGain.pdf)  \n",
    "  \n",
    "- [A. Kumar, “Accuracy, Precision, Recall & F1-Score - Python Examples - Data Analytics,” Data Analytics, Mar. 17, 2023. https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/. (accessed Aug. 10, 2023).‌](https://vitalflux.com/accuracy-precision-recall-f1-score-python-example/)  \n",
    "  \n",
    "- [J. Starmer, “Entropy (for data science) Clearly Explained!!!,” YouTube. Aug. 24, 2021. Accessed: Aug. 10, 2023. [YouTube Video]. Available: https://www.youtube.com/watch?v=YtebGVx-Fxw](https://www.youtube.com/watch?v=YtebGVx-Fxw)  \n",
    "\n",
    "- [\n",
    "Bharathi, “Latest Guide on Confusion Matrix for Multi-Class Classification,” Analytics Vidhya, Jun. 24, 2021. https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/ (accessed Aug. 10, 2023).‌](https://www.analyticsvidhya.com/blog/2021/06/confusion-matrix-for-multi-class-classification/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DecisionTree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
